## 3. Skills System Design

Agent Skills Architecture: We adopt the open Agent Skills format (initially developed by Anthropic and now industry-supported)

to define portable skills. In our system, a “skill” represents a self-contained capability or procedural knowledge set that an agent can use to perform a specific part of the workflow or a specialized task. All skills are stored canonically under agent/skills/<skill-name>/SKILL.md in the repository.

SKILL.md Format: Each SKILL.md consists of an optional YAML frontmatter followed by Markdown instructions. The frontmatter provides structured metadata about the skill, and the Markdown body provides the detailed guidance for the agent. For example, here is a simplified snippet for the plan skill:

```markdown
--- 
name: plan 
description: > 
  Decompose a project request into a step-by-step implementation plan, 
  including task breakdown, dependencies, and responsible agents. 
license: CC-BY-4.0 
compatibility: Works with any coding agent (Claude, Gemini, etc.) 
metadata:
  version: "1.0"
--- 

# Plan Skill

## When to Use
Use this skill at the beginning of a task, after clarifying requirements, to draft a detailed plan of action.

## How to Do It
1. **Analyze the request:** Restate the user’s goal and any constraints.
2. **Propose steps:** Break the goal into clear, ordered steps. For each step, consider:
   - What sub-problem it addresses.
   - Any prerequisite steps (dependencies).
   - Which agent/tool is best suited (if multi-agent), or "self" if the same agent will do it.
3. **Format the plan:** Output a structured list (YAML or JSON) with each step’s details (ID, description, owner, dependencies, status, etc.).
4. **Review:** Ensure the steps cover all requirements and are feasible given the environment and skills available.

## Example
_Input:_ "Add a feature to upload CSV files and display summary stats."  
_Output (plan excerpt):_
```yaml
steps:
- id: 1 
  description: "Create file upload UI in frontend" 
  owner: "UI-Agent" 
  deps: [] 
  criteria: "User can select a CSV and hit upload."
- id: 2 
  description: "Backend endpoint to receive CSV and compute stats" 
  owner: "API-Agent" 
  deps: [1] 
  criteria: "CSV data parsed; returns record count, mean, median."
...
```

This illustrative `SKILL.md` shows typical sections we encourage skill authors to include:
- **“When to Use”** – conditions or triggers for the skill (helps the agent decide *if* the skill is relevant):contentReference[oaicite:34]{index=34}:contentReference[oaicite:35]{index=35}.
- **“How to Do It”** – step-by-step guidance or best practices for performing the skill’s task.
- **Examples/Edge Cases** – concrete examples of inputs/outputs, or pitfalls to watch for.

Skills are essentially modular prompt templates or instructions. By packaging them in a Markdown file, we make them easy to maintain and version (and they’re somewhat human-readable for review). The agents will load these files as needed, rather than hardcoding lengthy instructions in a system prompt.

**Folder Structure and Extras:** Within each skill folder, we can include:
- **`scripts/`** directory for any helper scripts the skill might invoke (for example, the `verify` skill might have `scripts/run_tests.sh` that the agent can call to execute the test suite):contentReference[oaicite:36]{index=36}. Scripts can be in languages like Python, Bash, etc., depending on what the agent’s execution environment supports. We ensure scripts are self-contained and documented, since they might be executed autonomously:contentReference[oaicite:37]{index=37}.
- **`references/`** directory for additional documentation or data files:contentReference[oaicite:38]{index=38}. For instance, a `security` skill might have `references/OWASP_TOP10.md` if needed, or a `review` skill might include a `references/code_style.md` with detailed style conventions. Agents will only load these on demand (e.g., if the skill’s main instructions refer to them), which keeps the memory footprint lower:contentReference[oaicite:39]{index=39}.
- **`assets/`** for any static files (images, templates, etc.) if relevant:contentReference[oaicite:40]{index=40}. In a coding context this may be less used, but could include things like a configuration template file.

These additional files support a principle of **progressive disclosure**: the agent first only sees the minimal info (skill name & description), then the full `SKILL.md` when using the skill, and only loads deep reference or scripts when absolutely needed:contentReference[oaicite:41]{index=41}:contentReference[oaicite:42]{index=42}. This way we balance giving the agent powerful tools with minimizing unnecessary context load.

**Skill Discovery and Loading:** How do agents actually *use* these skills? The process is:

- **Discovery:** When an agent session starts (or when explicitly refreshed), the agent scans the configured skills directories (e.g. `.claude/skills/`, `.gemini/skills/`) for skill folders containing `SKILL.md`:contentReference[oaicite:43]{index=43}:contentReference[oaicite:44]{index=44}. It parses each `SKILL.md`’s YAML frontmatter to get the `name` and `description`:contentReference[oaicite:45]{index=45}:contentReference[oaicite:46]{index=46}. This metadata is then injected into the agent’s context (usually the system or developer prompt) in a compact form so the model knows what skills are available. For example, Claude and others use an XML-like listing of skills in the prompt, as shown below:

```xml
<available_skills>
  <skill>
    <name>plan</name>
    <description>Breaks down a project into a step-by-step implementation plan.</description>
    <location>/repo/.claude/skills/plan/SKILL.md</location>
  </skill>
  <skill>
    <name>execute</name>
    <description>Writes code to implement a given task or plan step, and makes commits.</description>
    <location>/repo/.claude/skills/execute/SKILL.md</location>
  </skill>
  <!-- other skills... -->
</available_skills>
```

This example follows the recommendation for Claude models to list skills in an XML section. The location field may be included for filesystem-based agents to know where to cat the file when needed. Tool-based agents (that don’t have direct file system access) might omit the path and instead have a built-in mechanism to fetch the skill by name.

  - Activation: When the agent is processing a user request or a current task, it will decide which skill (if any) is relevant. This is part of the agent’s chain-of-thought – e.g., if the user’s prompt is to generate a plan, the agent recognizes the plan skill should be used. Once it decides to use a skill, it will load the full content of SKILL.md (often by issuing an internal command like reading the file) and incorporate those instructions into its reasoning process. Think of it as a function call: the agent’s prompt now gets supplemented with, say, “(Agent calls on plan skill)…” followed by the content of plan/SKILL.md. The agent then follows those instructions to produce its next output.

  - Skill Execution (Scripts): If a skill’s instructions involve running a script (say the execute skill might instruct: “Once code is written, run scripts/run_tests.sh to verify”), the agent can use its toolset to execute it. For instance, Claude Code or Gemini can run shell commands in a sandbox. We allow such script usage but with safety checks (discussed under security and permission models). The skill frontmatter’s allowed-tools field can whitelist certain operations for this skill– for example, allowed-tools: Bash(npm:*) Bash(python:*) might tell the agent it’s pre-approved to run npm or python commands when using this skill.

  - Versioning Strategy: Each skill’s metadata can include a version number (as shown with "version": "1.0" above). This helps track updates. We plan to version skills semantically (major.minor.patch) and document changes in a changelog. Since skills are code-like content, updates would go through code review (discussed in Governance). If a skill update is not backward compatible with older agents, the compatibility field in frontmatter can note requirements (e.g., “Requires Claude Code 1.5 or later”). The tool adapters can use this info to only load compatible skills or warn if there’s a mismatch.

  - Compatibility Differences: While the skill content is meant to be universal, we recognize not all agent LLMs behave identically. Some might need slight tuning. For example, one model might respond better to very explicit instructions (“IMPORTANT: Do X”), whereas another might have a smaller context window requiring brevity. We will handle this by:

    - Keeping the canonical SKILL.md as neutral and tool-agnostic as possible.

    - If needed, use the compatibility frontmatter to note special handling, or include conditional sections in the Markdown (for instance, “(Note for GPT-3.5 based agents: do Y instead of Z)”). Agents can be instructed to ignore sections not for them.

    - In worst-case scenarios, we maintain slight variants in the tool-specific copy – but we aim to avoid divergence. The goal is one canonical skill definition that works across the board. The open standard encourages this by allowing one skill to be used by many agents.

Example Skill – execute: To further illustrate, the execute skill might be defined as follows (summary):

  - Name: execute

  - Description: Writes or modifies code according to a plan step, and performs the necessary actions to integrate it (running tests, formatting, committing code).

  - Instructions: “When activated, this skill guides the agent to: understand the task from the plan, open or create the relevant files in the codebase, write the code (explaining reasoning minimally in comments), run tests (npm test or similar) to verify, and if all passes, commit the changes with a meaningful message. If tests fail, identify the issues and attempt fixes (looping back to coding). Use caution with destructive operations (flag to user if something major is about to be changed).”

  - Scripts/References: perhaps a scripts/format.sh to auto-format code, or references to project coding conventions.

With such a skill in place, whenever an agent is ready to implement a step, it will load the execute skill and follow that process. Meanwhile, a verify skill might contain instructions on how to verify changes: run test suites, static analyzers, and confirm acceptance criteria, etc., and a report skill might outline how to summarize results for the user or produce a final diff/PR.

Agent-to-Agent Handoff via Skills: Another powerful use of skills is enabling one agent to delegate to another. For instance, a plan skill could include a step where the agent decides: “This plan step might be better done by a specialized agent. Use the coordinator to spawn a new agent.” In practice, delegation might be handled more by the plan schema and coordinator (next sections), but skills can mention it. We could have a skill like review which an executing agent can call after coding to get a second opinion (i.e., trigger the “Code Review Agent”). In our architecture, that would mean the agent writes a message or file that signals another agent (with the review skill knowledge) to start, effectively a controlled agent-to-agent handoff (the details of which are in the Plan format and workflow protocol).

In summary, the Skills system provides a modular library of behaviors. It ensures consistency (everyone uses the same instructions for the same task), reusability (skills can be applied by multiple agents or in different contexts), and extensibility (adding a new skill – e.g., a refactor skill – is as simple as adding a folder with a SKILL.md, which all compliant agents will automatically discover and be able to use). By leveraging the established Agent Skills spec, we align with a format that tools already understand, and our design benefits from community support and tooling (like validators, examples of good skills, etc.).

Next, we’ll address how agents coordinate work via a shared plan format and how one agent’s output (a plan or partial result) can be handed off to another agent for execution, which is crucial for multi-agent collaboration.